{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0maoc-cli 0.6.0\n",
      "\u001b[0mLoaded session cookie from \"/home/kev/.adventofcode.session\".\n",
      "Fetching puzzle for day 10, 2021...\n",
      "Saving puzzle description to \"README.md\"...\n",
      "Downloading input for day 10, 2021...\n",
      "Saving puzzle input to \"input.txt\"...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import statistics\n",
    "\n",
    "aoc_year, aoc_day = os.getcwd().split(os.sep)[-2:]\n",
    "\n",
    "# Download today puzzle & input\n",
    "!aoc --version\n",
    "!aoc download -i input.txt --overwrite -p README.md --year {aoc_year} --day {aoc_day}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\--- Day 10: Syntax Scoring ---\n",
    "----------\n",
    "\n",
    "You ask the submarine to determine the best route out of the deep-sea cave, but it only replies:\n",
    "\n",
    "```\n",
    "Syntax error in navigation subsystem on line: all of them\n",
    "```\n",
    "\n",
    "*All of them?!* The damage is worse than you thought. You bring up a copy of the navigation subsystem (your puzzle input).\n",
    "\n",
    "The navigation subsystem syntax is made of several lines containing *chunks*. There are one or more chunks on each line, and chunks contain zero or more other chunks. Adjacent chunks are not separated by any delimiter; if one chunk stops, the next chunk (if any) can immediately start. Every chunk must *open* and *close* with one of four legal pairs of matching characters:\n",
    "\n",
    "* If a chunk opens with `(`, it must close with `)`.\n",
    "* If a chunk opens with `[`, it must close with `]`.\n",
    "* If a chunk opens with `{`, it must close with `}`.\n",
    "* If a chunk opens with `<`, it must close with `>`.\n",
    "\n",
    "So, `()` is a legal chunk that contains no other chunks, as is `[]`. More complex but valid chunks include `([])`, `{()()()}`, `<([{}])>`, `[<>({}){}[([])<>]]`, and even `(((((((((())))))))))`.\n",
    "\n",
    "Some lines are *incomplete*, but others are *corrupted*. Find and discard the corrupted lines first.\n",
    "\n",
    "A corrupted line is one where a chunk *closes with the wrong character* - that is, where the characters it opens and closes with do not form one of the four legal pairs listed above.\n",
    "\n",
    "Examples of corrupted chunks include `(]`, `{()()()>`, `(((()))}`, and `<([]){()}[{}])`. Such a chunk can appear anywhere within a line, and its presence causes the whole line to be considered corrupted.\n",
    "\n",
    "For example, consider the following navigation subsystem:\n",
    "\n",
    "```\n",
    "[({(<(())[]>[[{[]{<()<>>\n",
    "[(()[<>])]({[<{<<[]>>(\n",
    "{([(<{}[<>[]}>{[]{[(<()>\n",
    "(((({<>}<{<{<>}{[]{[]{}\n",
    "[[<[([]))<([[{}[[()]]]\n",
    "[{[{({}]{}}([{[{{{}}([]\n",
    "{<[[]]>}<{[{[{[]{()[[[]\n",
    "[<(<(<(<{}))><([]([]()\n",
    "<{([([[(<>()){}]>(<<{{\n",
    "<{([{{}}[<[[[<>{}]]]>[]]\n",
    "\n",
    "```\n",
    "\n",
    "Some of the lines aren't corrupted, just incomplete; you can ignore these lines for now. The remaining five lines are corrupted:\n",
    "\n",
    "* `{([(<{}[<>[]}>{[]{[(<()>` - Expected `]`, but found `}` instead.\n",
    "* `[[<[([]))<([[{}[[()]]]` - Expected `]`, but found `)` instead.\n",
    "* `[{[{({}]{}}([{[{{{}}([]` - Expected `)`, but found `]` instead.\n",
    "* `[<(<(<(<{}))><([]([]()` - Expected `>`, but found `)` instead.\n",
    "* `<{([([[(<>()){}]>(<<{{` - Expected `]`, but found `>` instead.\n",
    "\n",
    "Stop at the first incorrect closing character on each corrupted line.\n",
    "\n",
    "Did you know that syntax checkers actually have contests to see who can get the high score for syntax errors in a file? It's true! To calculate the syntax error score for a line, take the *first illegal character* on the line and look it up in the following table:\n",
    "\n",
    "* `)`: `3` points.\n",
    "* `]`: `57` points.\n",
    "* `}`: `1197` points.\n",
    "* `>`: `25137` points.\n",
    "\n",
    "In the above example, an illegal `)` was found twice (`2*3 = *6*` points), an illegal `]` was found once (`*57*` points), an illegal `}` was found once (`*1197*` points), and an illegal `>` was found once (`*25137*` points). So, the total syntax error score for this file is `6+57+1197+25137 = *26397*` points!\n",
    "\n",
    "Find the first illegal character in each corrupted line of the navigation subsystem. *What is the total syntax error score for those errors?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{{<{{{{([{[([[()<>]{<>{}}]<([]())(()<>)>)((({}())[()[]])<<[][]>[{}[]]>)]{{(<{}<>>{<><>}]([<>[]]<',\n",
      " '[(<{{[{(<({{<<[]()><<>{}>>([<>[]]{<><>})}})>)}]}}>[{(<{({[{[[({}())((){})]({{}[]})]<<[<>{}]([][])>({<>()}',\n",
      " '(({<{[{({(([[([]())({}())]]({[[]{}]([][]))<((){})<{}<>>>))[(([<>[]]<[]>)(([]{}){{}{}}))])})[({<[{',\n",
      " '([{{[([<({<<<([]())[()[]]>{<()[]>[[]()]}>[{<[]{}><[]>>{<<>()>{[]()}}]>[[[[[]{}]([]<>)]<{<>{}}',\n",
      " '[[((<({<(<{<<{{}()}{[][]}>[((){})]>}>{((<({}<>)<{}()>>[[<>()]])<<<[][]><<>[]>>{<{}[]>(<>())}>)<{[[{',\n",
      " '[{<{{{{<([{[(<[]<>>(<>[])){({}<>)([]<>)}]{{([][])[<>{}]}{<[]<>>(<>{})}}}])<<{[<[<>{}]<(){}>>{<{}<>><<>']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "with open('input.txt', 'rt') as f:\n",
    "    lines = [x.strip() for x in f.readlines()]\n",
    "\n",
    "# Verify parse\n",
    "pprint(lines[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntax_lookup = {\n",
    "    \"(\": \")\",\n",
    "    \"[\": \"]\",\n",
    "    \"{\": \"}\",\n",
    "    \"<\": \">\",\n",
    "}\n",
    "syntax_score_lookup = {\n",
    "    \")\": 3,\n",
    "    \"]\": 57,\n",
    "    \"}\": 1197,\n",
    "    \">\": 25137,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_line_valid(line, syntax_lookup):\n",
    "    tokens = []\n",
    "    valid = True\n",
    "    for i, char in enumerate(list(line)):\n",
    "        if char in [\"(\", \"[\", \"{\", \"<\"]:\n",
    "            # Found opening token, append expected closing token to stack\n",
    "            tokens.append(syntax_lookup[char])\n",
    "        elif char in [\")\", \"]\", \"}\", \">\"]:\n",
    "            # Found closing token, validate against stack\n",
    "            if char != tokens.pop():\n",
    "                valid = False\n",
    "                break\n",
    "    return valid, i, char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = 0\n",
    "\n",
    "# Iterate over each line, if not valid accumulate score\n",
    "for line in lines:\n",
    "    valid, i, char = is_line_valid(line, syntax_lookup) \n",
    "    if not valid:\n",
    "        score += syntax_score_lookup[char]\n",
    "\n",
    "answer1 = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer 1: 362271\n"
     ]
    }
   ],
   "source": [
    "print(\"answer 1:\", answer1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded session cookie from \"/home/kev/.adventofcode.session\".\n",
      "Fetching puzzle for day 10, 2021...\n",
      "Saving puzzle description to \"README.md\"...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Download part 2\n",
    "!aoc download --description-only --overwrite --puzzle-file README.md --year {aoc_year} --day {aoc_day}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\--- Part Two ---\n",
    "----------\n",
    "\n",
    "Now, discard the corrupted lines. The remaining lines are *incomplete*.\n",
    "\n",
    "Incomplete lines don't have any incorrect characters - instead, they're missing some closing characters at the end of the line. To repair the navigation subsystem, you just need to figure out *the sequence of closing characters* that complete all open chunks in the line.\n",
    "\n",
    "You can only use closing characters (`)`, `]`, `}`, or `>`), and you must add them in the correct order so that only legal pairs are formed and all chunks end up closed.\n",
    "\n",
    "In the example above, there are five incomplete lines:\n",
    "\n",
    "* `[({(<(())[]>[[{[]{<()<>>` - Complete by adding `}}]])})]`.\n",
    "* `[(()[<>])]({[<{<<[]>>(` - Complete by adding `)}>]})`.\n",
    "* `(((({<>}<{<{<>}{[]{[]{}` - Complete by adding `}}>}>))))`.\n",
    "* `{<[[]]>}<{[{[{[]{()[[[]` - Complete by adding `]]}}]}]}>`.\n",
    "* `<{([{{}}[<[[[<>{}]]]>[]]` - Complete by adding `])}>`.\n",
    "\n",
    "Did you know that autocomplete tools *also* have contests? It's true! The score is determined by considering the completion string character-by-character. Start with a total score of `0`. Then, for each character, multiply the total score by 5 and then increase the total score by the point value given for the character in the following table:\n",
    "\n",
    "* `)`: `1` point.\n",
    "* `]`: `2` points.\n",
    "* `}`: `3` points.\n",
    "* `>`: `4` points.\n",
    "\n",
    "So, the last completion string above - `])}>` - would be scored as follows:\n",
    "\n",
    "* Start with a total score of `0`.\n",
    "* Multiply the total score by 5 to get `0`, then add the value of `]` (2) to get a new total score of `2`.\n",
    "* Multiply the total score by 5 to get `10`, then add the value of `)` (1) to get a new total score of `11`.\n",
    "* Multiply the total score by 5 to get `55`, then add the value of `}` (3) to get a new total score of `58`.\n",
    "* Multiply the total score by 5 to get `290`, then add the value of `>` (4) to get a new total score of `294`.\n",
    "\n",
    "The five lines' completion strings have total scores as follows:\n",
    "\n",
    "* `}}]])})]` - `288957` total points.\n",
    "* `)}>]})` - `5566` total points.\n",
    "* `}}>}>))))` - `1480781` total points.\n",
    "* `]]}}]}]}>` - `995444` total points.\n",
    "* `])}>` - `294` total points.\n",
    "\n",
    "Autocomplete tools are an odd bunch: the winner is found by *sorting* all of the scores and then taking the *middle* score. (There will always be an odd number of scores to consider.) In this example, the middle score is `*288957*` because there are the same number of scores smaller and larger than it.\n",
    "\n",
    "Find the completion string for each incomplete line, score the completion strings, and sort the scores. *What is the middle score?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "autocomplete_scores = {\n",
    "    ')': 1,\n",
    "    ']': 2,\n",
    "    '}': 3,\n",
    "    '>': 4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocomplete_line(line, syntax_lookup):\n",
    "    tokens = []\n",
    "    for i, char in enumerate(list(line)):\n",
    "        if char in [\"(\", \"[\", \"{\", \"<\"]:\n",
    "            # Found opening token, append expected closing token to stack\n",
    "            tokens.append(syntax_lookup[char])\n",
    "        elif char in [\")\", \"]\", \"}\", \">\"]:\n",
    "            # Found closing token, validate against stack\n",
    "            token = tokens.pop()\n",
    "            assert char == token, f\"[{i}] found {char} expected {token} {line}\"\n",
    "    #print(f\"{line} {''.join([_ for _ in reversed(tokens)])}\")\n",
    "    return [_ for _ in reversed(tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for line in lines:\n",
    "    valid, _, _ = is_line_valid(line, syntax_lookup)\n",
    "    if valid:\n",
    "        incomplete = autocomplete_line(line, syntax_lookup)\n",
    "        if len(incomplete) > 0:\n",
    "            score = 0\n",
    "            for token in incomplete:\n",
    "                score = 5 * score + autocomplete_scores[token]\n",
    "            scores.append(score)\n",
    "\n",
    "print(len(scores))\n",
    "answer2 = sorted(scores)[int(len(scores) / 2 + 0.5)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer 2: 1698395182\n"
     ]
    }
   ],
   "source": [
    "print(\"answer 2:\", answer2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
